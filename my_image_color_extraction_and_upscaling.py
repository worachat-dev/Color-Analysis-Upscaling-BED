# -*- coding: utf-8 -*-
"""My Image Color Extraction and Upscaling

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DhJoRIshD4rUda1KOyFf1Ke6N-vz5cPZ

My Python Jupyter Notebook for Google Colab that addresses the identified issues in the provided code and incorporates best practices for image color extraction by **Worachat Wannawong**, Ph.D. 2024:
"""

# Import necessary libraries
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt

# Mount your Google Drive if you want to access images from there (optional)
from google.colab import drive
drive.mount('/content/drive')  # Replace '/content/drive' with your desired mount point

# Define the image path (replace with your image URL or local path)
image_path = 'spiderman.jpg'  # You can use a URL or a path on your mounted Drive

# Open the image
try:
  img = Image.open(image_path)
except FileNotFoundError:
  print(f"Error: Image file '{image_path}' not found.")
  exit()

# Convert the image to a NumPy array for easier processing
img_array = np.array(img)

# Reshape the image data for K-Means clustering
w, h, d = img_array.shape  # Get image dimensions
pixels = img_array.reshape((w * h, d))

# Define the number of colors to extract
n_colors = 10

# Perform K-Means clustering to identify dominant colors
kmeans = KMeans(n_clusters=n_colors, random_state=42).fit(pixels)
dominant_colors = kmeans.cluster_centers_

# Convert the dominant colors to a format suitable for displaying in matplotlib
palette = dominant_colors.astype(np.uint8)

# Create a visualization of the extracted colors
plt.figure(figsize=(8, 6))  # Adjust figure size for better viewing
plt.imshow(palette)
plt.axis('off')
plt.title('Extracted Dominant Colors')
plt.show()

# Optional: Display the original image with color labels (using matplotlib)
def label_image(image, dominant_colors, labels):
  """
  Labels each pixel in the image with its corresponding dominant color cluster.

  Args:
      image: The image to label (NumPy array).
      dominant_colors: The cluster centers from K-Means (NumPy array).
      labels: The cluster labels for each pixel (NumPy array).

  Returns:
      A labeled image (NumPy array).
  """
  labeled_image = np.zeros_like(image)
  for i in range(image.shape[0]):
    for j in range(image.shape[1]):
      label = labels[i * image.shape[1] + j]
      labeled_image[i, j] = dominant_colors[label]
  return labeled_image

# Get cluster labels for each pixel
labels = kmeans.labels_.reshape((w, h))

# Label the image (optional)
labeled_img = label_image(img_array.copy(), dominant_colors, labels)
plt.imshow(labeled_img)
plt.axis('off')
plt.title('Original Image with Color Labels (Optional)')
plt.show()

"""**Key improvements:**

- **Error handling:** Checks if the image file exists to avoid errors.
- **Clear comments:** Explains each step for better understanding.
- **Optional Google Drive mounting:** Provides the option to access images from your Drive.
- **Meaningful variable names:** Uses descriptive names like `dominant_colors`.
- **Visualization:** Creates a clear plot of the extracted dominant colors.
- **Optional color labeling:** Offers an additional step to visualize dominant colors in the original image using `label_image` function (uncomment to use).
- **Code formatting:** Follows consistent indentation and spacing.

**To run this notebook in Google Colab:**

1. Create a new Jupyter Notebook.
2. Copy and paste the code into the notebook cells.
3. Replace `'spiderman.jpg'` with the actual path to your image (or mount your Drive and access it from there).
4. Run the cells one by one (Shift+Enter).

This enhanced code provides a robust, well-explained, and informative approach to extracting dominant colors from images in a Google Colab environment.
"""

# Import necessary libraries
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans # import the KMeans class from the sklearn.cluster module

# Mount your Google Drive if you want to access images from there (optional)
from google.colab import drive
drive.mount('/content/drive')  # Replace '/content/drive' with your desired mount point

# Define the image path (replace with your image URL or local path)
image_path = 'spiderman.jpg'  # You can use a URL or a path on your mounted Drive

# Open the image
try:
  img = Image.open(image_path)
except FileNotFoundError:
  print(f"Error: Image file '{image_path}' not found.")
  exit()

# Convert the image to a NumPy array for easier processing
img_array = np.array(img)

# Reshape the image data for K-Means clustering
w, h, d = img_array.shape  # Get image dimensions
pixels = img_array.reshape((w * h, d))

# Define the number of colors to extract
n_colors = 10

# Perform K-Means clustering to identify dominant colors
kmeans = KMeans(n_clusters=n_colors, random_state=42).fit(pixels)
dominant_colors = kmeans.cluster_centers_

# Convert the dominant colors to a format suitable for displaying in matplotlib
palette = dominant_colors.astype(np.uint8)

# Create a visualization of the extracted colors
plt.figure(figsize=(8, 6))  # Adjust figure size for better viewing
plt.imshow(palette)
plt.axis('off')
plt.title('Extracted Dominant Colors')
plt.show()

# Optional: Display the original image with color labels (using matplotlib)
def label_image(image, dominant_colors, labels):
  """
  Labels each pixel in the image with its corresponding dominant color cluster.

  Args:
      image: The image to label (NumPy array).
      dominant_colors: The cluster centers from K-Means (NumPy array).
      labels: The cluster labels for each pixel (NumPy array).

  Returns:
      A labeled image (NumPy array).
  """
  labeled_image = np.zeros_like(image)
  for i in range(image.shape[0]):
    for j in range(image.shape[1]):
      label = labels[i, j] # Access the label for the current pixel using i and j as indices
      labeled_image[i, j] = dominant_colors[label]
  return labeled_image

# Get cluster labels for each pixel
labels = kmeans.labels_.reshape((w, h))

# Label the image (optional)
labeled_img = label_image(img_array.copy(), dominant_colors, labels)
plt.imshow(labeled_img)
plt.axis('off')
plt.title('Original Image with Color Labels (Optional)')
plt.show()

def label_image(image, dominant_colors, labels):
  """
  Labels each pixel in the image with its corresponding dominant color cluster.

  Args:
      image: The image to label (NumPy array).
      dominant_colors: The cluster centers from K-Means (NumPy array).
      labels: The cluster labels for each pixel (NumPy array).

  Returns:
      A labeled image (NumPy array).
  """
  labeled_image = np.zeros_like(image)
  for i in range(image.shape[0]):
    for j in range(image.shape[1]):
      label = labels[i, j] # Access the label for the current pixel using i and j as indices
      labeled_image[i, j] = dominant_colors[label]
  return labeled_image

# Import necessary libraries
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

# Mount Google Drive to access files if needed (optional)
from google.colab import drive
drive.mount('/content/drive')  # Mount at this point if you're using files from Google Drive

# Define the image path
# Update this with your own path, for example: '/content/drive/MyDrive/spiderman.jpg'
image_path = 'spiderman.jpg'

# Open the image file
try:
    img = Image.open(image_path)
except FileNotFoundError:
    print(f"Error: Image file '{image_path}' not found. Please check the path.")
    exit()

# Convert the image to a NumPy array for processing
img_array = np.array(img)

# Reshape the image data for K-Means clustering
w, h, d = img_array.shape  # Get image dimensions
pixels = img_array.reshape((w * h, d))  # Flatten the image for clustering

# Set the number of dominant colors you want to extract
n_colors = 10

# Perform K-Means clustering to identify dominant colors
kmeans = KMeans(n_clusters=n_colors, random_state=42).fit(pixels)
dominant_colors = kmeans.cluster_centers_

# Convert the dominant colors into a format suitable for matplotlib display
palette = dominant_colors.astype(np.uint8)

# Visualize the extracted dominant colors
plt.figure(figsize=(8, 6))  # Adjust the figure size for better viewing
plt.imshow([palette])  # Show as a horizontal bar of colors
plt.axis('off')
plt.title('Extracted Dominant Colors')
plt.show()

# Function to label each pixel in the image based on its dominant color cluster
def label_image(image, dominant_colors, labels):
    """
    Labels each pixel in the image with its corresponding dominant color cluster.

    Args:
        image: The image to label (NumPy array).
        dominant_colors: The cluster centers from K-Means (NumPy array).
        labels: The cluster labels for each pixel (NumPy array).

    Returns:
        A labeled image (NumPy array).
    """
    labeled_image = np.zeros_like(image)
    for i in range(image.shape[0]):
        for j in range(image.shape[1]):
            label = labels[i, j]
            labeled_image[i, j] = dominant_colors[label]
    return labeled_image

# Get the labels assigned by K-Means to each pixel and reshape them
labels = kmeans.labels_.reshape((w, h))

# Create and display the image with color labels (optional)
labeled_img = label_image(img_array.copy(), dominant_colors, labels)
plt.imshow(labeled_img)
plt.axis('off')
plt.title('Original Image with Color Labels')
plt.show()

"""## Image Upscaling in Python Jupyter Notebook

**Understanding Image Upscaling**

Image upscaling is the process of increasing the resolution of an image, making it appear larger and sharper. There are various techniques for achieving this, including:

* **Nearest Neighbor Interpolation:** The simplest method, but often results in pixelated images.
* **Bilinear Interpolation:** A more sophisticated method that uses a weighted average of neighboring pixels.
* **Bicubic Interpolation:** A higher-quality method that uses a cubic polynomial to interpolate pixel values.
* **Deep Learning-based Methods:** These methods leverage neural networks to learn complex patterns in images and generate high-quality upscaled versions.

**Using OpenCV for Image Upscaling**

OpenCV is a popular computer vision library that provides efficient functions for image processing, including upscaling. Here's a Python Jupyter Notebook example using OpenCV:
"""

import cv2
import matplotlib.pyplot as plt

# Load the image
img = cv2.imread('spiderman.jpg')

# Upscale the image using bilinear interpolation
upscaled_img = cv2.resize(img, (0, 0), fx=2, fy=2, interpolation=cv2.INTER_LINEAR)

# Display the original and upscaled images
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
plt.title('Original Image')
plt.subplot(1, 2, 2)
plt.imshow(cv2.cvtColor(upscaled_img, cv2.COLOR_BGR2RGB))
plt.title('Upscaled Image')
plt.show()

"""**Explanation:**
1. **Import necessary libraries:** Import `cv2` for OpenCV functions and `matplotlib.pyplot` for image visualization.
2. **Load the image:** Use `cv2.imread()` to load the image you want to upscale.
3. **Upscale the image:** Use `cv2.resize()` to increase the image size. The `fx` and `fy` parameters specify the scaling factor in the x and y directions, respectively. `cv2.INTER_LINEAR` is used for bilinear interpolation.
4. **Display the images:** Use `plt.imshow()` to display the original and upscaled images.

**Additional Considerations:**

* **Deep Learning Methods:** For more advanced upscaling, consider using deep learning models like SRGAN or ESRGAN. These models can produce significantly better results, especially for low-resolution images.
* **Image Quality Metrics:** Evaluate the upscaled image using metrics like Peak Signal-to-Noise Ratio (PSNR) or Structural Similarity Index (SSIM) to assess its quality.
* **Other Interpolation Methods:** Explore other interpolation methods like bicubic (`cv2.INTER_CUBIC`) or Lanczos (`cv2.INTER_LANCZOS4`) for different trade-offs between speed and quality.

By following these steps and experimenting with different techniques, you can effectively upscale images in your Python Jupyter Notebook projects.

<div class="md-recitation">
  Sources
  <ol>
  <li><a href="https://github.com/DMF194/DUMP2">https://github.com/DMF194/DUMP2</a></li>
  </ol>
</div>
"""